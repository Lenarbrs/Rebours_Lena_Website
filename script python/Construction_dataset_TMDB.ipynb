{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0d535e",
   "metadata": {},
   "source": [
    "## Script de collecte TMDB ‚Äì Jeux de donn√©es par d√©cennies\n",
    "\n",
    "Ce script permet de r√©cup√©rer automatiquement, via l‚ÄôAPI TMDB, des films ann√©e par ann√©e, puis de les enrichir avec des informations d√©taill√©es (cast, crew, keywords, etc.), et de sauvegarder le tout dans Google Drive, organis√© par d√©cennies. \n",
    "\n",
    "Il sert de base √† la constitution du dataset n√©cessaire au projet de recommandation de contenus culturels pour l‚Äôapprentissage des langues.\n",
    "\n",
    "\n",
    "\n",
    "### Objectif du script\n",
    "\n",
    "- R√©cup√©rer un **grand volume de films** sur une p√©riode donn√©e (`start_year` ‚Üí `end_year`).\n",
    "- G√©rer les **limitations de TMDB** (pagination, limite √† 500 pages, popularit√©, etc.).\n",
    "- Compl√©ter chaque film avec :\n",
    "  - casting principal,\n",
    "  - r√©alisateurs,\n",
    "  - sc√©naristes,\n",
    "  - genres,\n",
    "  - pays et soci√©t√©s de production,\n",
    "  - langues parl√©es,\n",
    "  - mots-cl√©s,\n",
    "  - notes et popularit√©.\n",
    "- Sauvegarder les r√©sultats :\n",
    "  - par tranche de **10 ans** (`years_per_file`),\n",
    "  - dans des fichiers CSV s√©par√©s :\n",
    "    - un fichier `base` (r√©sultats bruts de discover),\n",
    "    - un fichier `full` (avec tous les d√©tails).\n",
    "\n",
    "### Pr√©requis\n",
    "\n",
    "- Environnement :\n",
    "  - Le script est pr√©vu pour **Google Colab** avec montage Google Drive.\n",
    "- Un compte TMDB + une **cl√© API valide**.\n",
    "\n",
    "### Organisation des fichiers\n",
    "\n",
    "Les fichiers sont enregistr√©s dans :\n",
    "\n",
    "```text\n",
    "/content/drive/MyDrive/tmdb_data_decennies_full_details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a90f1",
   "metadata": {},
   "source": [
    "### 1. Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b966be",
   "metadata": {},
   "source": [
    "### 2. R√©cup√©ration dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c2e7d",
   "metadata": {},
   "source": [
    "### 2.1. Connection √† Google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d49434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Connect to Google Drive ===\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# === 2. Create visible folder in Drive ===\n",
    "def ensure_drive_folder(path, note=\"TMDb full dataset folder created automatically by Colab\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    readme_path = os.path.join(path, \"README.txt\")\n",
    "    if not os.path.exists(readme_path):\n",
    "        with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(note)\n",
    "        print(f\"üìÅ Folder created and visible in Drive: {path}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Folder already exists: {path}\")\n",
    "\n",
    "save_dir = \"/content/drive/MyDrive/tmdb_data_decennies_full_details\"\n",
    "ensure_drive_folder(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dafe84",
   "metadata": {},
   "source": [
    "### 2.2. Requ√™te API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Configuration ===\n",
    "api_key = \"6fb1e958076fb0c90fdc8286a488f89f\"\n",
    "base_url = \"https://api.themoviedb.org/3/discover/movie\"\n",
    "start_year = 1950\n",
    "end_year = 2025\n",
    "years_per_file = 10\n",
    "language = \"en-US\"\n",
    "\n",
    "# === 4. Basic discover function ===\n",
    "def get_movies_by_period(start_date, end_date):\n",
    "    all_movies = []\n",
    "    page = 1\n",
    "    total_pages = 1\n",
    "\n",
    "    while page <= total_pages:\n",
    "        url = (\n",
    "            f\"{base_url}?api_key={api_key}&language={language}\"\n",
    "            f\"&primary_release_date.gte={start_date}\"\n",
    "            f\"&primary_release_date.lte={end_date}\"\n",
    "            f\"&sort_by=popularity.desc&page={page}\"\n",
    "        )\n",
    "        r = requests.get(url)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"‚ö†Ô∏è Error {r.status_code} between {start_date} and {end_date} (page {page})\")\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "\n",
    "        data = r.json()\n",
    "        total_pages = min(data.get(\"total_pages\", 0), 500)\n",
    "        all_movies.extend(data.get(\"results\", []))\n",
    "        page += 1\n",
    "\n",
    "        if page % 40 == 0:\n",
    "            time.sleep(10)\n",
    "    return pd.DataFrame(all_movies)\n",
    "\n",
    "# === 5. Full details (cast, crew, etc.) ===\n",
    "def get_movie_details(movie_id):\n",
    "    \"\"\"Return complete movie details including cast, crew, budget, etc.\"\"\"\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{movie_id}?api_key={api_key}&language={language}&append_to_response=credits,keywords,recommendations,reviews\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    data = r.json()\n",
    "\n",
    "    # Extract main cast & crew\n",
    "    cast = [c[\"name\"] for c in data.get(\"credits\", {}).get(\"cast\", [])[:5]]\n",
    "    directors = [c[\"name\"] for c in data.get(\"credits\", {}).get(\"crew\", []) if c.get(\"job\") == \"Director\"]\n",
    "    writers = [c[\"name\"] for c in data.get(\"credits\", {}).get(\"crew\", []) if c.get(\"department\") == \"Writing\"]\n",
    "\n",
    "    # Keywords\n",
    "    keywords = [k[\"name\"] for k in data.get(\"keywords\", {}).get(\"keywords\", [])]\n",
    "\n",
    "    return {\n",
    "        \"id\": data.get(\"id\"),\n",
    "        \"title\": data.get(\"title\"),\n",
    "        \"original_title\": data.get(\"original_title\"),\n",
    "        \"overview\": data.get(\"overview\"),\n",
    "        \"release_date\": data.get(\"release_date\"),\n",
    "        \"runtime\": data.get(\"runtime\"),\n",
    "        \"budget\": data.get(\"budget\"),\n",
    "        \"revenue\": data.get(\"revenue\"),\n",
    "        \"genres\": [g[\"name\"] for g in data.get(\"genres\", [])],\n",
    "        \"production_companies\": [p[\"name\"] for p in data.get(\"production_companies\", [])],\n",
    "        \"production_countries\": [c[\"name\"] for c in data.get(\"production_countries\", [])],\n",
    "        \"spoken_languages\": [l[\"english_name\"] for l in data.get(\"spoken_languages\", [])],\n",
    "        \"popularity\": data.get(\"popularity\"),\n",
    "        \"vote_average\": data.get(\"vote_average\"),\n",
    "        \"vote_count\": data.get(\"vote_count\"),\n",
    "        \"cast\": cast,\n",
    "        \"directors\": directors,\n",
    "        \"writers\": writers,\n",
    "        \"keywords\": keywords\n",
    "    }\n",
    "\n",
    "# === 6. Download one year (with fallback to months if needed) ===\n",
    "def get_movies_by_year(year):\n",
    "    print(f\"üé¨ Downloading movies from {year} ...\")\n",
    "    df_year = get_movies_by_period(f\"{year}-01-01\", f\"{year}-12-31\")\n",
    "\n",
    "    if len(df_year) >= 9500:\n",
    "        print(f\"‚ö†Ô∏è {year}: limit reached ({len(df_year)} movies). Splitting by month ...\")\n",
    "        dfs_months = []\n",
    "        for month in range(1, 13):\n",
    "            start = f\"{year}-{month:02d}-01\"\n",
    "            end = f\"{year}-{month+1:02d}-01\" if month < 12 else f\"{year+1}-01-01\"\n",
    "            df_m = get_movies_by_period(start, end)\n",
    "            dfs_months.append(df_m)\n",
    "        df_year = pd.concat(dfs_months, ignore_index=True)\n",
    "\n",
    "    print(f\"‚úÖ {len(df_year)} movies collected for {year}\")\n",
    "    return df_year\n",
    "\n",
    "# === 7. Enrich each movie with full details ===\n",
    "def enrich_with_details(df, decade_path):\n",
    "    details_list = []\n",
    "    existing_ids = set()\n",
    "\n",
    "    if os.path.exists(decade_path):\n",
    "        df_existing = pd.read_csv(decade_path)\n",
    "        existing_ids = set(df_existing[\"id\"])\n",
    "        print(f\"‚ôªÔ∏è {len(existing_ids)} movies already saved, resuming...\")\n",
    "\n",
    "    for movie_id in tqdm(df[\"id\"], desc=\"Fetching details\"):\n",
    "        if movie_id in existing_ids:\n",
    "            continue\n",
    "        details = get_movie_details(movie_id)\n",
    "        if details:\n",
    "            details_list.append(details)\n",
    "\n",
    "        # Rate limit\n",
    "        if len(details_list) % 40 == 0:\n",
    "            time.sleep(10)\n",
    "\n",
    "        # Sauvegarde tous les 500 films\n",
    "        if len(details_list) % 500 == 0:\n",
    "            pd.DataFrame(details_list).to_csv(decade_path, mode='a', index=False, header=not os.path.exists(decade_path))\n",
    "            details_list = []\n",
    "\n",
    "    # Derni√®re sauvegarde\n",
    "    if details_list:\n",
    "        pd.DataFrame(details_list).to_csv(decade_path, mode='a', index=False, header=not os.path.exists(decade_path))\n",
    "\n",
    "# === 8. Download each decade ===\n",
    "for decade_start in tqdm(range(start_year, end_year + 1, years_per_file)):\n",
    "    decade_end = min(decade_start + years_per_file - 1, end_year)\n",
    "    base_file = f\"{save_dir}/films_{decade_start}_{decade_end}_base.csv\"\n",
    "    full_file = f\"{save_dir}/films_{decade_start}_{decade_end}_full.csv\"\n",
    "\n",
    "    if not os.path.exists(base_file):\n",
    "        print(f\"\\nüìÖ Downloading base movies for {decade_start}-{decade_end} ...\")\n",
    "        dfs = []\n",
    "        for year in range(decade_start, decade_end + 1):\n",
    "            df_y = get_movies_by_year(year)\n",
    "            dfs.append(df_y)\n",
    "\n",
    "            # ‚úÖ Confirmation annuelle\n",
    "            print(f\"üìÖ ‚úÖ YEAR {year} DONE ‚Äî {len(df_y)} movies collected so far.\\n\")\n",
    "            time.sleep(2)\n",
    "\n",
    "        df_decade = pd.concat(dfs, ignore_index=True)\n",
    "        df_decade.to_csv(base_file, index=False, encoding=\"utf-8\")\n",
    "        print(f\"üíæ {len(df_decade)} base movies saved in {base_file}\")\n",
    "    else:\n",
    "        print(f\"‚è© Base file already exists for {decade_start}-{decade_end}\")\n",
    "\n",
    "    # Step 2: enrich with details\n",
    "    df_base = pd.read_csv(base_file)\n",
    "    print(f\"üîç Enriching {len(df_base)} movies with full details ...\")\n",
    "    enrich_with_details(df_base, full_file)\n",
    "    print(f\"‚úÖ Full dataset saved: {full_file}\\n\")\n",
    "\n",
    "print(\"\\nüéâ COMPLETE DOWNLOAD FINISHED! All full datasets are in your Drive (tmdb_data_decennies_full_details)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
