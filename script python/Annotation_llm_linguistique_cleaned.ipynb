{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45eba005",
   "metadata": {},
   "source": [
    "# Annotation linguistique de films \n",
    "\n",
    "Ce notebook transforme un export TMDB en un dataset utilisable pour de l'annotation linguistique.\n",
    "\n",
    "**Pipeline**\n",
    "1. Nettoyage du CSV brut (valeurs manquantes, types numériques, filtre `popularity != 0`).\n",
    "2. Filtre langue : on garde uniquement les films où la **langue originale** est bien dans `spoken_languages`.\n",
    "3. (Optionnel) Filtre des langues **rares** pour réduire les cas trop niche.\n",
    "4. Attribution de labels heuristiques : `linguistic_level`, `linguistic_register`, `linguistic_exposure`, + `score` et `confidence`.\n",
    "\n",
    "## Fichiers produits\n",
    "- `films_TMDB_clean_filtered.csv`\n",
    "- `films_language_match_only.csv`\n",
    "- `films_language_match_only_filtered_rare_spoken50.csv` (optionnel)\n",
    "- `films_language_match_only_with_linguistic_labels_v2.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183a94c",
   "metadata": {},
   "source": [
    "# 0) Library Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25befe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# PARAMETRES (à adapter)\n",
    "# ----------------------------\n",
    "RAW_CSV = Path('films_TMDB_all_reordered_clean_no_runtime_0.csv')\n",
    "CLEAN_CSV = Path('films_TMDB_clean_filtered.csv')\n",
    "MATCH_CSV = Path('films_language_match_only.csv')\n",
    "FILTERED_CSV = Path('films_language_match_only_filtered_rare_spoken50.csv')\n",
    "LABELED_CSV = Path('films_language_match_only_with_linguistic_labels_v2.csv')\n",
    "\n",
    "# Filtre \"langues rares\" (nombre d'apparitions dans spoken_languages)\n",
    "RARE_THRESHOLD = 50\n",
    "\n",
    "# Pour les sanity checks (cellule tout en bas)\n",
    "EXCLUDE_ORIG = {'en'}\n",
    "MIN_VOTE_COUNT_FOR_QA = 300\n",
    "TOP_N_QA = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2399f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Helpers parsing (robustes)\n",
    "# ----------------------------\n",
    "\n",
    "def parse_py_list(x):\n",
    "    # Retourne une liste Python depuis NaN / list / string-literal\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    s = str(x).strip()\n",
    "    if not s or s in ['[]', '{}']:\n",
    "        return []\n",
    "    if (s.startswith('[') and s.endswith(']')) or (s.startswith('{') and s.endswith('}')):\n",
    "        try:\n",
    "            v = ast.literal_eval(s)\n",
    "            return v if isinstance(v, list) else []\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "# ISO -> Nom (pour comparer original_language à spoken_languages)\n",
    "ISO_TO_LANG = {\n",
    "    'en': 'English', 'fr': 'French', 'es': 'Spanish', 'ja': 'Japanese', 'de': 'German',\n",
    "    'ru': 'Russian', 'pt': 'Portuguese', 'it': 'Italian', 'zh': 'Chinese', 'ko': 'Korean',\n",
    "    'hi': 'Hindi', 'ar': 'Arabic', 'sv': 'Swedish', 'nl': 'Dutch', 'pl': 'Polish',\n",
    "    'tr': 'Turkish', 'fa': 'Persian', 'el': 'Greek', 'fi': 'Finnish', 'da': 'Danish',\n",
    "    'no': 'Norwegian', 'he': 'Hebrew', 'cs': 'Czech', 'hu': 'Hungarian', 'ro': 'Romanian',\n",
    "    'th': 'Thai', 'vi': 'Vietnamese', 'id': 'Indonesian', 'ms': 'Malay', 'uk': 'Ukrainian',\n",
    "    'bg': 'Bulgarian', 'sr': 'Serbian', 'hr': 'Croatian', 'sk': 'Slovak', 'lt': 'Lithuanian',\n",
    "    'lv': 'Latvian', 'et': 'Estonian', 'sl': 'Slovenian', 'ca': 'Catalan', 'bn': 'Bengali',\n",
    "    'ta': 'Tamil', 'te': 'Telugu', 'ml': 'Malayalam', 'kn': 'Kannada', 'mr': 'Marathi',\n",
    "    'gu': 'Gujarati', 'pa': 'Punjabi', 'ur': 'Urdu', 'ne': 'Nepali', 'sw': 'Swahili',\n",
    "    'zu': 'Zulu', 'xh': 'Xhosa', 'af': 'Afrikaans'\n",
    "}\n",
    "\n",
    "def _lang_name_from_item(item):\n",
    "    # item: dict TMDB (english_name/name/iso_639_1) ou string\n",
    "    if isinstance(item, dict):\n",
    "        v = item.get('english_name') or item.get('name') or item.get('iso_639_1')\n",
    "        return str(v).strip() if v else None\n",
    "    if item is None:\n",
    "        return None\n",
    "    s = str(item).strip()\n",
    "    return s if s else None\n",
    "\n",
    "def parse_spoken_languages(x):\n",
    "    # Sortie: liste de noms (ex: ['English','French'])\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "\n",
    "    # 1) déjà liste\n",
    "    if isinstance(x, list):\n",
    "        out = []\n",
    "        for it in x:\n",
    "            name = _lang_name_from_item(it)\n",
    "            if name:\n",
    "                out.append(name)\n",
    "        return out\n",
    "\n",
    "    s = str(x).strip()\n",
    "    if not s or s in ['[]', '{}']:\n",
    "        return []\n",
    "\n",
    "    # 2) tentative parse python-literal\n",
    "    if (s.startswith('[') and s.endswith(']')) or (s.startswith('{') and s.endswith('}')):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(s)\n",
    "            if isinstance(parsed, list):\n",
    "                out = []\n",
    "                for it in parsed:\n",
    "                    name = _lang_name_from_item(it)\n",
    "                    if name:\n",
    "                        out.append(name)\n",
    "                return out\n",
    "            if isinstance(parsed, dict):\n",
    "                name = _lang_name_from_item(parsed)\n",
    "                return [name] if name else []\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 3) fallback split texte (\"English, French\" etc.)\n",
    "    parts = re.split(r\"[;,/|]\\s*|\\s*,\\s*\", s)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "\n",
    "def to_numeric_safe(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4634f42",
   "metadata": {},
   "source": [
    "## 1) Nettoyage du CSV brut\n",
    "\n",
    "- Remplacement des \"fausses valeurs manquantes\" (`\"\"`, `\"None\"`, `[]`, `{}` ...)\n",
    "- Conversion de colonnes numériques\n",
    "- Suppression des lignes avec NaN sur les colonnes **critiques**\n",
    "- Suppression des films avec `popularity == 0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce674d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RAW_CSV.exists():\n",
    "    raise FileNotFoundError(f\"Fichier introuvable: {RAW_CSV.resolve()}\")\n",
    "\n",
    "# Chargement\n",
    "raw = pd.read_csv(RAW_CSV)\n",
    "print('RAW shape:', raw.shape)\n",
    "\n",
    "# Nettoyage des fausses valeurs manquantes\n",
    "fake_nan_patterns = {\n",
    "    r'^\\s*$': np.nan,\n",
    "    r'(?i)^(none|null|nan)$': np.nan,\n",
    "    r'^\\[\\s*\\]$': np.nan,\n",
    "    r'^\\{\\s*\\}$': np.nan,\n",
    "}\n",
    "raw = raw.replace(fake_nan_patterns, regex=True)\n",
    "\n",
    "# Conversion numériques\n",
    "numeric_cols = ['popularity','vote_average','vote_count','budget','revenue','runtime','year']\n",
    "raw = to_numeric_safe(raw, numeric_cols)\n",
    "\n",
    "# Colonnes autorisées à être manquantes\n",
    "allowed_nan = [\n",
    "    'poster_path','backdrop_path','revenue','cast','directors','writers','keywords',\n",
    "    'adult','video','production_companies','production_countries'\n",
    "]\n",
    "allowed_nan = [c for c in allowed_nan if c in raw.columns]\n",
    "critical_cols = [c for c in raw.columns if c not in allowed_nan]\n",
    "\n",
    "before = len(raw)\n",
    "clean = raw.dropna(subset=critical_cols).copy()\n",
    "\n",
    "# Filtre popularity != 0\n",
    "if 'popularity' in clean.columns:\n",
    "    clean = clean[clean['popularity'].notna() & (clean['popularity'] != 0)].copy()\n",
    "\n",
    "print('Dropped (NaN on critical cols):', before - len(clean))\n",
    "print('CLEAN shape:', clean.shape)\n",
    "\n",
    "clean.to_csv(CLEAN_CSV, index=False)\n",
    "print('Saved:', CLEAN_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b83b9",
   "metadata": {},
   "source": [
    "## 2) Analyse rapide des langues \n",
    "\n",
    "On vérifie la distribution des langues pour savoir un peu avec quoi on travaille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04363d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CLEAN_CSV)\n",
    "\n",
    "# Comptage langues originales\n",
    "if 'original_language' in df.columns:\n",
    "    print('=== original_language (top 20) ===')\n",
    "    print(df['original_language'].value_counts().head(20).to_string())\n",
    "\n",
    "# Comptage langues parlées\n",
    "if 'spoken_languages' in df.columns:\n",
    "    spoken = []\n",
    "    for v in df['spoken_languages'].dropna():\n",
    "        spoken += parse_spoken_languages(v)\n",
    "\n",
    "    counts = Counter(spoken)\n",
    "    print('\\n=== spoken_languages (top 20) ===')\n",
    "    for lang, c in counts.most_common(20):\n",
    "        print(f'{lang}: {c}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590bfff",
   "metadata": {},
   "source": [
    "## 3) Filtre: garder uniquement les films où la langue originale est parlée\n",
    "\n",
    "On garde un film si :\n",
    "- `original_language` (code ISO) **ou** son nom (via `ISO_TO_LANG`) est présent dans `spoken_languages`.\n",
    "\n",
    "Sortie : `films_language_match_only.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a768ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CLEAN_CSV)\n",
    "\n",
    "if 'original_language' not in df.columns or 'spoken_languages' not in df.columns:\n",
    "    raise ValueError('Colonnes requises manquantes: original_language / spoken_languages')\n",
    "\n",
    "keep_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    orig_code = row.get('original_language')\n",
    "    if pd.isna(orig_code):\n",
    "        continue\n",
    "\n",
    "    orig_code = str(orig_code).strip()\n",
    "    orig_name = ISO_TO_LANG.get(orig_code, orig_code)\n",
    "\n",
    "    spoken = set(parse_spoken_languages(row.get('spoken_languages')))\n",
    "\n",
    "    # check: nom ou code\n",
    "    if (orig_name in spoken) or (orig_code in spoken):\n",
    "        keep_rows.append(row)\n",
    "\n",
    "matched = pd.DataFrame(keep_rows)\n",
    "print('Before:', len(df), '| After match:', len(matched))\n",
    "matched.to_csv(MATCH_CSV, index=False)\n",
    "print('Saved:', MATCH_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccdbe0c",
   "metadata": {},
   "source": [
    "## 4) (Optionnel) Filtre des langues rares\n",
    "\n",
    "Règles (comme dans ton notebook initial) :\n",
    "- **A**: si `spoken_languages` contient 1 seule langue et qu'elle est rare (< `RARE_THRESHOLD`) → supprimer\n",
    "- **B**: si plusieurs langues mais que la langue originale est rare → supprimer\n",
    "\n",
    "Sortie : `films_language_match_only_filtered_rare_spoken50.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(MATCH_CSV)\n",
    "\n",
    "# Comptage de chaque langue parlée (1 fois par film)\n",
    "spoken_counter = Counter()\n",
    "spoken_sets = []\n",
    "for v in df['spoken_languages']:\n",
    "    langs = set(parse_spoken_languages(v))\n",
    "    spoken_sets.append(langs)\n",
    "    for lang in langs:\n",
    "        spoken_counter[lang] += 1\n",
    "\n",
    "rare_langs = {lang for lang, c in spoken_counter.items() if c < RARE_THRESHOLD}\n",
    "print(f'Rare langs (<{RARE_THRESHOLD}):', len(rare_langs))\n",
    "\n",
    "rows_to_keep = []\n",
    "removed_by_lang = defaultdict(int)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    langs = spoken_sets[idx]\n",
    "    if not langs:\n",
    "        rows_to_keep.append(row)\n",
    "        continue\n",
    "\n",
    "    orig_code = str(row.get('original_language')).strip()\n",
    "    orig_name = ISO_TO_LANG.get(orig_code, orig_code)\n",
    "\n",
    "    # Règle A\n",
    "    if len(langs) == 1:\n",
    "        only_lang = next(iter(langs))\n",
    "        if only_lang in rare_langs:\n",
    "            removed_by_lang[only_lang] += 1\n",
    "            continue\n",
    "\n",
    "    # Règle B\n",
    "    if orig_name in rare_langs:\n",
    "        removed_by_lang[orig_name] += 1\n",
    "        continue\n",
    "\n",
    "    rows_to_keep.append(row)\n",
    "\n",
    "filtered = pd.DataFrame(rows_to_keep)\n",
    "print('Before:', len(df), '| After rare-filter:', len(filtered), '| Removed:', len(df) - len(filtered))\n",
    "\n",
    "if removed_by_lang:\n",
    "    print('\\nTop langues ayant entraîné des suppressions:')\n",
    "    for lang, c in sorted(removed_by_lang.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "        print(f'{lang}: {c}')\n",
    "\n",
    "filtered.to_csv(FILTERED_CSV, index=False)\n",
    "print('Saved:', FILTERED_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258a422",
   "metadata": {},
   "source": [
    "## 5) Attribution de labels linguistiques (heuristiques)\n",
    "\n",
    "On calcule un **score de difficulté** puis on en déduit :\n",
    "- `linguistic_level` : Débutant / Intermédiaire / Avancé\n",
    "- `linguistic_register` : Familier / Courant / Soutenu\n",
    "- `linguistic_exposure` : Forte / Moyenne / Faible (1,2,3+ langues parlées)\n",
    "- `linguistic_confidence` : proxy basé sur `vote_count` (stabilité) et multilinguisme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f544cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix de l'entrée : filtrée rare (si elle existe) sinon match-only\n",
    "input_for_labels = FILTERED_CSV if FILTERED_CSV.exists() else MATCH_CSV\n",
    "print('Using input:', input_for_labels)\n",
    "\n",
    "df = pd.read_csv(input_for_labels)\n",
    "\n",
    "# Conversions utiles\n",
    "for c in ['vote_count','vote_average','popularity','runtime','year','linguistic_difficulty_score']:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Genres: on accepte list, string-literal, ou texte\n",
    "\n",
    "def parse_genres(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(v).strip() for v in x if str(v).strip()]\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    # format list-literal\n",
    "    if s.startswith('[') and s.endswith(']'):\n",
    "        try:\n",
    "            v = ast.literal_eval(s)\n",
    "            if isinstance(v, list):\n",
    "                return [str(it).strip() for it in v if str(it).strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "    # fallback texte \"A, B\"\n",
    "    return [p.strip() for p in re.split(r\"[;,/]\\s*|\\s*,\\s*\", s) if p.strip()]\n",
    "\n",
    "# Spoken languages -> set de noms\n",
    "spoken_sets = df['spoken_languages'].apply(lambda x: set(parse_spoken_languages(x)) if 'spoken_languages' in df.columns else set())\n",
    "\n",
    "# Comptage global des langues (1 fois par film)\n",
    "lang_counter = Counter()\n",
    "for langs in spoken_sets:\n",
    "    for l in langs:\n",
    "        lang_counter[l] += 1\n",
    "\n",
    "# Poids par genre (à ajuster)\n",
    "genre_weight = {\n",
    "    # plutôt accessible\n",
    "    'Animation': -0.7,\n",
    "    'Family': -0.7,\n",
    "    'TV Movie': -0.6,\n",
    "    'Adventure': -0.25,\n",
    "    'Fantasy': -0.10,\n",
    "    'Romance': -0.20,\n",
    "    'Music': -0.15,\n",
    "    'Comedy': -0.10,\n",
    "\n",
    "    # neutre\n",
    "    'Action': 0.00,\n",
    "    'Science Fiction': 0.10,\n",
    "    'Horror': 0.20,\n",
    "\n",
    "    # plus dense\n",
    "    'Drama': 0.45,\n",
    "    'Thriller': 0.45,\n",
    "    'Mystery': 0.55,\n",
    "    'Crime': 0.55,\n",
    "\n",
    "    # souvent exigeant\n",
    "    'Documentary': 0.85,\n",
    "    'History': 0.95,\n",
    "    'War': 0.95,\n",
    "    'Western': 0.55,\n",
    "}\n",
    "\n",
    "# Helpers score\n",
    "\n",
    "def safe_float(x, default=np.nan):\n",
    "    try:\n",
    "        v = float(x)\n",
    "        return v\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def safe_int(x, default=None):\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return default\n",
    "        return int(float(x))\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def is_mainstream(popularity, vote_count):\n",
    "    pop = safe_float(popularity, 0.0)\n",
    "    vc = safe_float(vote_count, 0.0)\n",
    "    return (pop >= 25 and vc >= 500) or (vc >= 2500)\n",
    "\n",
    "def epic_bonus(genre_set, runtime):\n",
    "    if runtime is None:\n",
    "        return 0.0\n",
    "    if runtime >= 150 and ('History' in genre_set or 'War' in genre_set):\n",
    "        return 0.55\n",
    "    if runtime >= 160 and ('Drama' in genre_set and ('History' in genre_set or 'War' in genre_set)):\n",
    "        return 0.65\n",
    "    if runtime >= 180 and ('Drama' in genre_set):\n",
    "        return 0.35\n",
    "    return 0.0\n",
    "\n",
    "def rarity_bonus(spoken_set):\n",
    "    b = 0.0\n",
    "    for l in spoken_set:\n",
    "        c = lang_counter.get(l, 0)\n",
    "        if c < 10:\n",
    "            b = max(b, 0.8)\n",
    "        elif c < 50:\n",
    "            b = max(b, 0.5)\n",
    "        elif c < 200:\n",
    "            b = max(b, 0.2)\n",
    "    return b\n",
    "\n",
    "def multilingual_penalty(spoken_set, mainstream_flag):\n",
    "    n = len(spoken_set)\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    pen = 0.10 * (n - 1)\n",
    "    if mainstream_flag:\n",
    "        pen *= 0.25\n",
    "    if (n >= 5) and (not mainstream_flag):\n",
    "        pen += 0.35\n",
    "    return min(pen, 0.9)\n",
    "\n",
    "def difficulty_score(row, spoken_set):\n",
    "    score = 2.0\n",
    "\n",
    "    genres = parse_genres(row.get('genres'))\n",
    "    gset = set(genres)\n",
    "\n",
    "    score += sum(genre_weight.get(g, 0.0) for g in genres)\n",
    "\n",
    "    rt = safe_float(row.get('runtime'), default=np.nan)\n",
    "    runtime = None if np.isnan(rt) else rt\n",
    "\n",
    "    if runtime is not None:\n",
    "        if runtime < 80:\n",
    "            score -= 0.15\n",
    "        if runtime > 140:\n",
    "            score += 0.20\n",
    "        if runtime > 180:\n",
    "            score += 0.35\n",
    "\n",
    "    pop = safe_float(row.get('popularity'), 0.0)\n",
    "    vc = safe_float(row.get('vote_count'), 0.0)\n",
    "    mainstream_flag = is_mainstream(pop, vc)\n",
    "\n",
    "    if mainstream_flag:\n",
    "        score -= 0.20\n",
    "    elif vc < 25:\n",
    "        score += 0.15\n",
    "\n",
    "    score += multilingual_penalty(spoken_set, mainstream_flag)\n",
    "\n",
    "    score += rarity_bonus(spoken_set) * (0.6 if mainstream_flag else 1.0)\n",
    "\n",
    "    score += epic_bonus(gset, runtime)\n",
    "\n",
    "    year = safe_int(row.get('year'), default=None)\n",
    "    if year is not None and year < 1980:\n",
    "        score += 0.15\n",
    "    if year is not None and year < 1960:\n",
    "        score += 0.20\n",
    "\n",
    "    return score\n",
    "\n",
    "def level_from_score(s):\n",
    "    if s < 1.7:\n",
    "        return 'Débutant'\n",
    "    elif s < 3.4:\n",
    "        return 'Intermédiaire'\n",
    "    return 'Avancé'\n",
    "\n",
    "def register_label(row, spoken_set, score):\n",
    "    genres = set(parse_genres(row.get('genres')))\n",
    "    year = safe_int(row.get('year'), default=2000)\n",
    "    rt = safe_float(row.get('runtime'), default=np.nan)\n",
    "    runtime = None if np.isnan(rt) else rt\n",
    "\n",
    "    r = 0.0\n",
    "\n",
    "    if any(g in genres for g in ['Documentary','History','War']):\n",
    "        r += 1.1\n",
    "    if 'Drama' in genres:\n",
    "        r += 0.25\n",
    "    if year is not None and year < 1970:\n",
    "        r += 0.35\n",
    "\n",
    "    if runtime is not None and runtime >= 150 and ('Fantasy' in genres and 'Adventure' in genres):\n",
    "        r += 0.55\n",
    "\n",
    "    if any(g in genres for g in ['Animation','Family','Comedy']):\n",
    "        r -= 0.95\n",
    "    if year is not None and year >= 2000 and ('Comedy' in genres or 'Romance' in genres):\n",
    "        r -= 0.15\n",
    "\n",
    "    if score >= 4.2:\n",
    "        r += 0.15\n",
    "\n",
    "    if r >= 0.65:\n",
    "        return 'Soutenu'\n",
    "    if r <= -0.55:\n",
    "        return 'Familier'\n",
    "    return 'Courant'\n",
    "\n",
    "def exposure_label(spoken_set):\n",
    "    n = len(spoken_set)\n",
    "    if n <= 1:\n",
    "        return 'Forte'\n",
    "    if n == 2:\n",
    "        return 'Moyenne'\n",
    "    return 'Faible'\n",
    "\n",
    "def confidence(row, spoken_set):\n",
    "    vc = safe_float(row.get('vote_count'), 0.0)\n",
    "    pop = safe_float(row.get('popularity'), 0.0)\n",
    "    mainstream_flag = is_mainstream(pop, vc)\n",
    "\n",
    "    base = 1 - np.exp(-vc / 250)  # 0..1\n",
    "    n = len(spoken_set)\n",
    "\n",
    "    penalty = 0.06 * max(0, n - 2)\n",
    "    if mainstream_flag:\n",
    "        penalty *= 0.35\n",
    "\n",
    "    return float(np.clip(base - penalty, 0.0, 1.0))\n",
    "\n",
    "# Annotation\n",
    "scores, levels, registers, exposures, confs = [], [], [], [], []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    sp = spoken_sets.iloc[i] if hasattr(spoken_sets, 'iloc') else spoken_sets[i]\n",
    "    s = difficulty_score(row, sp)\n",
    "    scores.append(s)\n",
    "    levels.append(level_from_score(s))\n",
    "    exposures.append(exposure_label(sp))\n",
    "    registers.append(register_label(row, sp, s))\n",
    "    confs.append(confidence(row, sp))\n",
    "\n",
    "# Ajout colonnes\n",
    "\n",
    "df['linguistic_difficulty_score'] = np.round(scores, 3)\n",
    "df['linguistic_level'] = levels\n",
    "df['linguistic_register'] = registers\n",
    "df['linguistic_exposure'] = exposures\n",
    "df['linguistic_confidence'] = np.round(confs, 3)\n",
    "\n",
    "# Aperçu\n",
    "cols_show = [\n",
    "    c for c in [\n",
    "        'title','year','original_language','genres','spoken_languages','runtime','vote_count',\n",
    "        'linguistic_level','linguistic_register','linguistic_exposure','linguistic_difficulty_score','linguistic_confidence'\n",
    "    ]\n",
    "    if c in df.columns\n",
    "]\n",
    "print('\\n=== Aperçu (Top 25 vote_count) ===')\n",
    "print(df.sort_values('vote_count', ascending=False)[cols_show].head(25).to_string(index=False))\n",
    "\n",
    "# Sauvegarde\n",
    "\n",
    "df.to_csv(LABELED_CSV, index=False)\n",
    "print('\\nSaved:', LABELED_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da51691",
   "metadata": {},
   "source": [
    "## 6) Sanity checks par langue (aide à la validation manuelle)\n",
    "\n",
    "- On exclut par défaut l'anglais (`EXCLUDE_ORIG`)\n",
    "- On limite aux films avec un `vote_count` minimum\n",
    "- On affiche : top connus, top difficile, top facile, répartitions, cas suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LABELED_CSV.exists():\n",
    "    raise FileNotFoundError(\"Le CSV labelisé est introuvable. Lance la cellule précédente.\")\n",
    "\n",
    "df = pd.read_csv(LABELED_CSV)\n",
    "\n",
    "# conversions\n",
    "for c in [\n",
    "    'vote_count', 'vote_average', 'popularity', 'runtime',\n",
    "    'linguistic_difficulty_score', 'year', 'linguistic_confidence'\n",
    "]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# filtre hors langues exclues\n",
    "if 'original_language' in df.columns:\n",
    "    df = df[~df['original_language'].isin(EXCLUDE_ORIG)].copy()\n",
    "\n",
    "# filtre vote_count\n",
    "if 'vote_count' in df.columns:\n",
    "    df = df[df['vote_count'].fillna(0) >= MIN_VOTE_COUNT_FOR_QA].copy()\n",
    "\n",
    "cols_show = [\n",
    "    c for c in [\n",
    "        'title','original_title','year','original_language','spoken_languages','genres','runtime',\n",
    "        'vote_average','vote_count','popularity','linguistic_level','linguistic_register','linguistic_exposure',\n",
    "        'linguistic_difficulty_score','linguistic_confidence'\n",
    "    ] if c in df.columns\n",
    "]\n",
    "\n",
    "langs = sorted(df['original_language'].dropna().unique()) if 'original_language' in df.columns else []\n",
    "\n",
    "def print_block(title, subdf, n=TOP_N_QA):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    if len(subdf) == 0:\n",
    "        print('(vide)')\n",
    "        return\n",
    "    print(subdf.head(n)[cols_show].to_string(index=False))\n",
    "\n",
    "\n",
    "def count_langs(x):\n",
    "    if pd.isna(x):\n",
    "        return 0\n",
    "    s = str(x).strip()\n",
    "    # list-literal\n",
    "    if s.startswith('[') and s.endswith(']'):\n",
    "        try:\n",
    "            v = ast.literal_eval(s)\n",
    "            if isinstance(v, list):\n",
    "                return len(set(parse_spoken_languages(v)))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return len(set(parse_spoken_languages(s)))\n",
    "\n",
    "for lang in langs:\n",
    "    sub = df[df['original_language'] == lang].copy()\n",
    "    if len(sub) == 0:\n",
    "        continue\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(f\"LANGUE ORIGINALE = {lang} | n={len(sub)} (vote_count >= {MIN_VOTE_COUNT_FOR_QA})\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    if 'vote_count' in sub.columns:\n",
    "        print_block(\n",
    "            f\"Top {TOP_N_QA} (vote_count) — films connus\",\n",
    "            sub.sort_values('vote_count', ascending=False)\n",
    "        )\n",
    "\n",
    "    if 'linguistic_difficulty_score' in sub.columns:\n",
    "        print_block(\n",
    "            f\"Top {TOP_N_QA} (difficulté la + haute)\",\n",
    "            sub.sort_values('linguistic_difficulty_score', ascending=False)\n",
    "        )\n",
    "        print_block(\n",
    "            f\"Top {TOP_N_QA} (difficulté la + basse)\",\n",
    "            sub.sort_values('linguistic_difficulty_score', ascending=True)\n",
    "        )\n",
    "\n",
    "    if 'linguistic_level' in sub.columns:\n",
    "        print(\"\\n--- Répartition linguistic_level ---\")\n",
    "        print(sub['linguistic_level'].value_counts(dropna=False).to_string())\n",
    "\n",
    "    if 'linguistic_register' in sub.columns:\n",
    "        print(\"\\n--- Répartition linguistic_register ---\")\n",
    "        print(sub['linguistic_register'].value_counts(dropna=False).to_string())\n",
    "\n",
    "    if 'linguistic_exposure' in sub.columns:\n",
    "        print(\"\\n--- Répartition linguistic_exposure ---\")\n",
    "        print(sub['linguistic_exposure'].value_counts(dropna=False).to_string())\n",
    "\n",
    "    if 'spoken_languages' in sub.columns:\n",
    "        sub['n_spoken'] = sub['spoken_languages'].apply(count_langs)\n",
    "\n",
    "        if {'linguistic_confidence', 'linguistic_difficulty_score'}.issubset(sub.columns):\n",
    "            suspects = sub[\n",
    "                (sub['linguistic_confidence'].fillna(1) < 0.80)\n",
    "                | (sub['n_spoken'] >= 4)\n",
    "                | (sub['linguistic_difficulty_score'] > 4.5)\n",
    "                | (sub['linguistic_difficulty_score'] < 0.8)\n",
    "            ].copy()\n",
    "\n",
    "            suspects = suspects.sort_values(\n",
    "                ['linguistic_confidence', 'n_spoken', 'linguistic_difficulty_score'],\n",
    "                ascending=[True, False, False]\n",
    "            )\n",
    "\n",
    "            print_block('CAS SUSPECTS (à vérifier manuellement)', suspects, n=TOP_N_QA)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
